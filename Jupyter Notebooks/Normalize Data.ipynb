{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "#This notebook further sets up data for creating visualizations and for performing analysis\n",
    "#----------------------------------------------\n",
    "%matplotlib notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os as os\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import median_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read and store the merged clean data and population data\n",
    "event_data = os.path.join('..','Cleaned Data','Merged_Clean_Data.csv')\n",
    "pop_data = os.path.join('..','Cleaned Data','Zillow_Population_Return.csv')\n",
    "\n",
    "event_df = pd.read_csv(event_data)\n",
    "pop_df = pd.read_csv(pop_data)\n",
    "\n",
    "event_df = event_df.drop(event_df.columns[0], axis = 1)\n",
    "pop_df = pop_df.drop(pop_df.columns[0], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty list for normalized event and population time series data\n",
    "n = 6\n",
    "event_lists = [[] for i in range(n)]\n",
    "pop_lists = [[] for j in range(n)]\n",
    "\n",
    "\n",
    "#create dictionary with data columns desired prior to adding normalized time series data\n",
    "normalized_dict = {'title' : event_df['Title'], 'disaster number' : event_df['Disaster Number'],\n",
    "                          'DisasterType' : event_df['Incident Type'], 'Declaration Date' : event_df['Declaration Date'],\n",
    "                          'Zip Code' : event_df['RegionName'], 'County' : event_df['CountyName']}\n",
    "\n",
    "#loop through empty event lists and then loop through event dataframe to populate empty event lists using declaration date to determine column index\n",
    "event_list_count = -1\n",
    "for x in event_lists:\n",
    "    event_list_count += 1\n",
    "    for index, row in event_df.iterrows():\n",
    "        ddate = row['Declaration Date']\n",
    "        try:\n",
    "            col_idx = event_df.columns.get_loc(ddate)\n",
    "            event_lists[event_list_count].append(row.iloc[col_idx + event_list_count + 1])\n",
    "        except:\n",
    "            event_lists[event_list_count].append(np.nan)\n",
    "\n",
    "#loop through empty population lists and then loop through population dataframe to populate empty event lists using declaration date from event dataframe to determine column index\n",
    "pop_list_count = -1\n",
    "for y in pop_lists:\n",
    "    pop_list_count += 1 \n",
    "    for index, row in event_df.iterrows():\n",
    "        ddate = row['Declaration Date']\n",
    "        try:\n",
    "            col_idx = pop_df.columns.get_loc(ddate)\n",
    "            pop_lists[pop_list_count].append(pop_df.iloc[0, col_idx + pop_list_count + 1])\n",
    "        except:\n",
    "            pop_lists[pop_list_count].append(np.nan)\n",
    "\n",
    "#loop through populated event lists and add key, value pairs to normalized_dict\n",
    "event_key_count = -1\n",
    "for a in event_lists:\n",
    "    event_key_count += 1\n",
    "    normalized_dict.update({f't+{event_key_count + 1}': event_lists[event_key_count]})\n",
    "\n",
    "#loop through populated population lists and add key, value pairs to normalized_dict\n",
    "pop_key_count = -1\n",
    "for b in pop_lists:\n",
    "    pop_key_count += 1\n",
    "    normalized_dict.update({f't+{pop_key_count + 1}p': pop_lists[pop_key_count]})\n",
    "\n",
    "#create data frame from normalized_dict\n",
    "normalized_df = pd.DataFrame(normalized_dict)\n",
    "\n",
    "#clean normalized_df of rows with NaN\n",
    "normalized_clean_df = normalized_df.dropna()\n",
    "\n",
    "normalized_clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_clean_df['DisasterType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_clean_df = normalized_clean_df.set_index(['DisasterType', 'Zip Code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_clean_df.to_csv('../Cleaned Data/Normalized_Clean_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create individual dataframes for each disaster type to chart later\n",
    "flood_df = normalized_clean_df.loc['Flood', :]\n",
    "flood_df.to_csv('../Cleaned Data/Flood_Data.csv')\n",
    "\n",
    "\n",
    "hurricane_df = normalized_clean_df.loc['Hurricane', :]\n",
    "hurricane_df.to_csv('../Cleaned Data/Hurricane_Data.csv')\n",
    "\n",
    "\n",
    "fire_df = normalized_clean_df.loc['Fire', :]\n",
    "fire_df.to_csv('../Cleaned Data/Fire_Data.csv')\n",
    "\n",
    "\n",
    "storms_df = normalized_clean_df.loc['Severe Storm(s)', :]\n",
    "storms_df.to_csv('../Cleaned Data/Storms_Data.csv')\n",
    "\n",
    "\n",
    "snow_df = normalized_clean_df.loc['Snow', :]\n",
    "snow_df.to_csv('../Cleaned Data/Snow_Data.csv')\n",
    "\n",
    "\n",
    "ice_df = normalized_clean_df.loc['Severe Ice Storm', :]\n",
    "ice_df.to_csv('../Cleaned Data/Ice_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test for the first Month\n",
    "housing = flood_df['t+1']\n",
    "pop = flood_df['t+1p']\n",
    "\n",
    "stats.median_test(housing, pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test for the Second Month\n",
    "housing = flood_df['t+2']\n",
    "pop = flood_df['t+2p']\n",
    "\n",
    "stats.median_test(housing, pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test for the third Month\n",
    "housing = flood_df['t+3']\n",
    "pop = flood_df['t+3p']\n",
    "\n",
    "stats.median_test(housing, pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test for the fourth Month\n",
    "housing = flood_df['t+4']\n",
    "pop = flood_df['t+4p']\n",
    "\n",
    "stats.median_test(housing, pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test for the fifth Month\n",
    "housing = flood_df['t+5']\n",
    "pop = flood_df['t+5p']\n",
    "\n",
    "stats.median_test(housing, pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test for the sixth Month\n",
    "housing = flood_df['t+6']\n",
    "pop = flood_df['t+6p']\n",
    "\n",
    "stats.median_test(housing, pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe that captures median time series for each disaster and population\n",
    "\n",
    "median_dict = {}\n",
    "\n",
    "flood_list = []\n",
    "hurricane_list = []\n",
    "fire_list = []\n",
    "storms_list = []\n",
    "snow_list = []\n",
    "ice_list = []\n",
    "pop_list = []\n",
    "\n",
    "for i, j in flood_df.loc[:,'t+1':'t+6'].iteritems():\n",
    "    flood_list.append(j.median())\n",
    "\n",
    "for i, j in hurricane_df.loc[:,'t+1':'t+6'].iteritems():\n",
    "    hurricane_list.append(j.median())\n",
    "\n",
    "for i, j in fire_df.loc[:,'t+1':'t+6'].iteritems():\n",
    "    fire_list.append(j.median())\n",
    "\n",
    "for i, j in storms_df.loc[:,'t+1':'t+6'].iteritems():\n",
    "    storms_list.append(j.median())\n",
    "\n",
    "for i, j in snow_df.loc[:,'t+1':'t+6'].iteritems():\n",
    "    snow_list.append(j.median())\n",
    "\n",
    "for i, j in ice_df.loc[:,'t+1':'t+6'].iteritems():\n",
    "    ice_list.append(j.median())\n",
    "\n",
    "for i, j in normalized_clean_df.loc[:,'t+1p':'t+6p'].iteritems():\n",
    "    pop_list.append(j.median())\n",
    "\n",
    "median_dict.update({'flood_median' : flood_list,\n",
    "                    'hurricane_median' : hurricane_list,\n",
    "                    'fire_median' : fire_list,\n",
    "                    'storms_median' : storms_list,\n",
    "                    'snow_median' : snow_list,\n",
    "                    'ice_median' : ice_list,\n",
    "                    'pop_median' : pop_list})\n",
    "\n",
    "median_df = pd.DataFrame(median_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add series to median_df that calculates increase in housing value based on normalized base\n",
    "\n",
    "base = 100000\n",
    "\n",
    "median_df['flood_cgrowth($)'] = (median_df['flood_median'] + 1).cumprod() * base\n",
    "median_df['hurricane_cgrowth($)'] = (median_df['hurricane_median'] + 1).cumprod() * base\n",
    "median_df['fire_cgrowth($)'] = (median_df['fire_median'] + 1).cumprod() * base\n",
    "median_df['storms_cgrowth($)'] = (median_df['storms_median'] + 1).cumprod() * base\n",
    "median_df['snow_cgrowth($)'] = (median_df['snow_median'] + 1).cumprod() * base\n",
    "median_df['ice_cgrowth($)'] = (median_df['ice_median'] + 1).cumprod() * base\n",
    "median_df['pop_cgrowth($)'] = (median_df['pop_median'] + 1).cumprod() * base\n",
    "\n",
    "median_df.to_csv('../Cleaned Data/Median_Data.csv')\n",
    "median_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
